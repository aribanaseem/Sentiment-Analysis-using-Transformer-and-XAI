# -*- coding: utf-8 -*-
"""Movie review analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0pJ15b8IY4GqdaiuxHIH700VC55zjpk
"""

!pip install transformers
!pip install torch
!pip install scikit-learn
!pip install pandas
!pip install lime
!pip install nltk

import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import pipeline
from lime.lime_text import LimeTextExplainer
import torch

# Load a ready-to-use BERT sentiment analysis model from HuggingFace
classifier = pipeline('sentiment-analysis')

# Try predicting a review
text = "I absolutely loved this movie. The acting was great and the plot was engaging!"

# Predict sentiment
print(classifier(text))

# Create a LIME text explainer
explainer = LimeTextExplainer(class_names=["NEGATIVE", "POSITIVE"])

# LIME needs a function that returns prediction probabilities
def predict_proba(texts):
    results = classifier(texts)
    # Convert to probability-like format for LIME
    return [[res['score'], 1 - res['score']] if res['label'] == 'POSITIVE' else [1 - res['score'], res['score']] for res in results]

def predict_proba(texts):
    results = classifier(texts)
    probabilities = []
    for res in results:
        if res['label'] == 'POSITIVE':
            probabilities.append([1 - res['score'], res['score']])  # [NEG, POS]
        else:
            probabilities.append([res['score'], 1 - res['score']])  # [NEG, POS]
    return np.array(probabilities)  # <-- this is critical

text_to_explain = "The movie was boring and too long. I wouldn't recommend it."

explanation = explainer.explain_instance(
    text_to_explain,
    predict_proba,
    num_features=10
)

# View explanation in notebook
explanation.show_in_notebook(text=True)

print("Top words contributing to prediction:")
for word, weight in explanation.as_list():
    print(f"{word}: {weight:.4f}")

